<?xml version="1.0"?>
<launch>

	<!-- Converts bounding box to image -->
	<node type="bb2image.py" name="image2bbYolo" pkg="image_inverse_sensor_model" respawn="true" output="screen">
		<param name="topicInName" value="/yolo/BBox/Multisense" />
		<param name="imageWidth" value="512" />  	<!-- Half of 1024 is selected 1024/2 = 512 -->
		<param name="imageHeight" value="217" />	<!-- Half of 544 is selected 544/2= 217 -->
		<param name="objectType_human" value="True" />
		<param name="objectType_vehicle" value="True" />
		<param name="objectType_animal" value="True" />
		<param name="objectType_obstacle" value="True" />
	</node>

	<!-- Use perspektive mapping to transform a detection image to an inverse sensor model -->
	<node type="image2ism.py" name="image2ismYolo" pkg="image_inverse_sensor_model" respawn="true" output="screen">
		<param name="topicIns" value="/det/Multisense/yolo/human /det/Multisense/yolo/vehicle /det/Multisense/yolo/animal /det/Multisense/yolo/obstacle" />
		<param name="cam_FOV" value="0.78345" />	<!-- Half DiagonalFOV 1.5669/2 = 0.78345. This is found using calibration found in Demo_CalibrationCheckerBoardMiniSensorKit.m -->
		<param name="imageWidth" value="512" />  	<!-- Half of 1024 is selected = 512 -->
		<param name="imageHeight" value="217" />	<!-- Half of 544 is selected = 217 -->
		<param name="grid_resolution" value="0.25" />

		<param name="cam_xTranslation" value="0.2038" /> 
		<param name="cam_yTranslation" value="0.255" />
		<param name="cam_zTranslation" value="2.056" />
		<param name="cam_pitch" value="0.1963" />  
		<param name="cam_yaw" value="0.0" />
	</node>

</launch>
