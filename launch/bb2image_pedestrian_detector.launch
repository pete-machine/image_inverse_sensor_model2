<launch>
	<!-- Converts bounding box to image -->
	<node type="bb2image.py" name="image2bbPed" pkg="image_inverse_sensor_model" respawn="true" output="screen">
		<param name="topicInName" value="/ped/BBox/Multisense/" />
		<param name="image_width" value="512" />  	<!-- Half of 1024 is selected = 512 -->
		<param name="image_height" value="217" />	<!-- Half of 544 is selected = 217 -->
		<param name="objectType_unknown" value="False" />
		<param name="objectType_vehicle" value="False" />
		<param name="objectType_human" value="True" />
	</node>

	<!-- Use perspektive mapping to transform a detection image to an inverse sensor model -->
	<node type="image2ism.py" name="image2ismPedestrian" pkg="image_inverse_sensor_model" respawn="true" output="screen">
		<param name="topicIns" value="/det/Multisense/ped/human" />
		<param name="cam_FOV" value="0.78345" />	<!-- Half DiagonalFOV 1.5669/2 = 0.78345. This is found using calibration found in Demo_CalibrationCheckerBoardMiniSensorKit.m -->
		<param name="imageWidth" value="512" />  	<!-- Half of 1024 is selected = 512 -->
		<param name="imageHeight" value="217" />	<!-- Half of 544 is selected = 217 -->

		<param name="grid_resolution" value="0.5" />

		<param name="cam_xTranslation" value="0.2038" /> 
		<param name="cam_yTranslation" value="0.255" />
		<param name="cam_zTranslation" value="2.056" />
		<param name="cam_pitch" value="0.1963" />  
		<param name="cam_yaw" value="0.0" />
	</node>

</launch>
